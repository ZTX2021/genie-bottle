model:
  tokenizer_ckpt_path: './data/log/genie-tokenizer/your_checkpoint.ckpt'
  tokenizer:
    class_path: genie.VideoTokenizer
    init_args:
      enc_desc:
        - - spacetime_downsample
          - in_channels : 3
            kernel_size : 3
            out_channels : 64
            time_factor : 1
            space_factor : 2
        - - space-time_attn
          - n_rep: 8
            n_head: 8
            d_head: 64
      dec_desc:
        - - space-time_attn
          - n_rep: 8
            n_head: 8
            d_head: 64
        - - depth2spacetime_upsample
          - in_channels : 64
            kernel_size : 3
            out_channels : 3
            time_factor : 1
            space_factor : 2
      disc_kwargs:
        inp_size: [64, 64] # Size of input frames
        model_dim: 32 # Dimension of the model
        dim_mults: [1, 2] # Channel multipliers
        down_step: [null, 2, 2] # Down-sampling steps
        inp_channels: 3
        kernel_size: 3
        num_groups: 8
        act_fn: leaky # Use LeakyReLU as activation function
        use_blur: True # Use BlurPooling for down-sampling
        use_attn: True # Discriminator can have spatial attention
        num_heads: 2 # Number of (spatial) attention heads
        dim_head: 16 # Dimension of each spatial attention heads
      #
      d_codebook: 2
      n_codebook: 1
      #
      lfq_bias: True
      lfq_frac_sample: 1
      lfq_commit_weight: 0.25
      lfq_entropy_weight: 0.01
      lfq_diversity_weight: 1.
      #
      optimizer:
        class_path: torch.optim.AdamW
        init_args:
          lr: 1e-3
          weight_decay: 0.01
      #
      perceptual_model: vgg16
      perc_feat_layers: [features.6, features.13, features.18, features.25]
      gan_discriminate: frames
      gan_frames_per_batch: 4
      gan_loss_weight: 0.0
      perc_loss_weight: 0.0
      quant_loss_weight: 1.
  optimizer: torch.optim.AdamW
  img_prompt: null

data:
  root: 'data'
  randomize: true
  num_frames: 16
  batch_size: 4
  output_format: 'c t h w'
  num_workers: 4

trainer:
  max_epochs: 8
  accelerator: gpu
  devices: 1
  precision: '16-mixed'
  log_every_n_steps: 16
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        save_last: true
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: './data/log'
      name: 'genie_training'

seed_everything: 42
